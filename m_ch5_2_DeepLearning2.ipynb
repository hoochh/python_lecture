{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab5769f-fb5c-48d1-8e4c-a46a21e159aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b698af02-9be6-457b-8b5f-c1b215bdf816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x= 1e-4\n",
    "    grad=np.zeros_like(x) \n",
    "    # 수치미분 결과를 grad에 저장\n",
    "    # x와 똑같은 shape을 가진 배열(혹은 행렬) 생성 (요소값은 0임)\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #모든 입력변수에 대해 편미분하기 위해 iterator 획득\n",
    "    # iterator 하나 생성. 플래그는 멀티 인덱스 설정\n",
    "    # 멀티 인덱스를 설정하면 다차원 배열이라도 \n",
    "    # 순차적으로 interator 생성 후 값을 꺼낼 수 있음\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        \n",
    "        tmp_val=x[idx] \n",
    "        # 임시 변수로 x[idx] 의 원값을 저장\n",
    "        # numpy 타입은 mutable 이므로 원래 값 보관\n",
    "        \n",
    "        x[idx]=float(tmp_val)+delta_x # 전향 차분\n",
    "        fx1=f(x) #f(x+delta_x) # 첫번째 인자로 들어온 함수를 대입\n",
    "        \n",
    "        x[idx]=tmp_val-delta_x # 후향 차분\n",
    "        fx2=f(x) #f(x-delta_x) # 첫번째 인자로 들어온 함수를 다시 대입\n",
    "        \n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x) # 미분 결과를 grad에...\n",
    "        \n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bad33888-0771-4781-b9c9-7f19a4a6197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogicGate Class\n",
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name\n",
    "        \n",
    "        #입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4, 2) \n",
    "        #__xdata에서 언더바 2개 : 밖에서 못 쓰는 것\n",
    "        # 4 개의 입력데이터 x1,x2에 대하여 batch 처리 행렬\n",
    "        self.__tdata = tdata.reshape(4, 1) \n",
    "        # 4 개의 입력데이터 x1,x2에 대한 각각의 계산 값 행렬\n",
    "        \n",
    "        #가중치 W2, 바이어스 b2 초기화\n",
    "        # 2층 hidden layer unit: 6개 가정\n",
    "        # 은닉층의 node는 임의의 수(여기선 6개)\n",
    "        self.__W2 = np.random.rand(2, 6)\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        \n",
    "        #가중치 W3, 바이어스 b3 초기화\n",
    "        # 3층 output layer unit: 1개\n",
    "        self.__W3 = np.random.rand(6, 1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "        \n",
    "        # Deep Learning 규칙 : 앞 layer의 출력과 뒷 layer의 입력 개수를 맞춰야 함\n",
    "        \n",
    "        #학습률 learining rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "        print(self.name+\"object is created\")\n",
    "        \n",
    "    def feed_forward(self): # feed forward를 통하여 손실함수(cross-entropy) 값 계산\n",
    "        \n",
    "        delta=1e-7 # log 무한대 발산 방지\n",
    "        \n",
    "        z2=np.dot(self.__xdata, self.__W2) + self.__b2 # 은닉층의 선형회귀 값\n",
    "        a2=sigmoid(z2) # 은닉층의 출력\n",
    "        \n",
    "        z3=np.dot(a2, self.__W3) + self.__b3 # 출력층의 선형회귀 값\n",
    "        y=sigmoid(z3) # 출력층의 출력\n",
    "        \n",
    "        # cross-entropy\n",
    "        return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
    "        \n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta =1e-7\n",
    "        \n",
    "        z2=np.dot(self.__xdata, self.__W2) + self.__b2 # 은닉층의 선형회귀 값\n",
    "        a2=sigmoid(z2) # 은닉층의 출력\n",
    "        \n",
    "        z3=np.dot(a2, self.__W3) + self.__b3 # 출력층의 선형회귀 값\n",
    "        y=sigmoid(z3) # 출력층의 출력\n",
    "        \n",
    "        # cross-entropy\n",
    "        return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
    "        \n",
    "    \n",
    "    #수치미분을 이용하여 손실함수가 최소가 될 때까지 학습하는 함수\n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "        \n",
    "        for step in range(16001):\n",
    "            \n",
    "            #gradient decent 하기 위한 작업\n",
    "            # 은닉층, 출력층 함께 작성\n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "            \n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "            \n",
    "            #error값이 400의 배수인 것 출력\n",
    "            if (step % 400 == 0):\n",
    "                print(\"Step = \", step, \"loss value =\", self.loss_val())\n",
    "\n",
    "    #미래값 예측\n",
    "    def predict(self, xdata):\n",
    "        \n",
    "        z2 = np.dot(xdata, self.__W2) + self.__b2 #은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3 # 출력층의 선형회귀 값\n",
    "        y = sigmoid(z3) # 출력층의 출력\n",
    "    \n",
    "        if y >= 0.5:\n",
    "            result = 1  #True\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e7949d2-108c-4db3-8931-6d30c53b87d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANDobject is created\n",
      "Initial loss value =  7.735810060436853\n",
      "Step =  0 loss value = 7.439223216159709\n",
      "Step =  400 loss value = 2.198987142509861\n",
      "Step =  800 loss value = 2.0852377083614275\n",
      "Step =  1200 loss value = 1.9124293213766077\n",
      "Step =  1600 loss value = 1.656900859194088\n",
      "Step =  2000 loss value = 1.3343015619058258\n",
      "Step =  2400 loss value = 1.0034025864229537\n",
      "Step =  2800 loss value = 0.7286498176076506\n",
      "Step =  3200 loss value = 0.5345440326198325\n",
      "Step =  3600 loss value = 0.40392749428585983\n",
      "Step =  4000 loss value = 0.31479168171239524\n",
      "Step =  4400 loss value = 0.2522549395859329\n",
      "Step =  4800 loss value = 0.20709362375461154\n",
      "Step =  5200 loss value = 0.17357333521083518\n",
      "Step =  5600 loss value = 0.1480616379437018\n",
      "Step =  6000 loss value = 0.1282039389727859\n",
      "Step =  6400 loss value = 0.11243619530333089\n",
      "Step =  6800 loss value = 0.09969394980430127\n",
      "Step =  7200 loss value = 0.08923572741831194\n",
      "Step =  7600 loss value = 0.08053368951848333\n",
      "Step =  8000 loss value = 0.07320446687900561\n",
      "Step =  8400 loss value = 0.06696445169718043\n",
      "Step =  8800 loss value = 0.061600284305269204\n",
      "Step =  9200 loss value = 0.05694897507725534\n",
      "Step =  9600 loss value = 0.05288426018969156\n",
      "Step =  10000 loss value = 0.049307069133642696\n",
      "Step =  10400 loss value = 0.04613875430423364\n",
      "Step =  10800 loss value = 0.04331620821903559\n",
      "Step =  11200 loss value = 0.040788291727026124\n",
      "Step =  11600 loss value = 0.03851318655197433\n",
      "Step =  12000 loss value = 0.03645640879253656\n",
      "Step =  12400 loss value = 0.03458930130163956\n",
      "Step =  12800 loss value = 0.03288787731223497\n",
      "Step =  13200 loss value = 0.03133192466783105\n",
      "Step =  13600 loss value = 0.029904305494564302\n",
      "Step =  14000 loss value = 0.028590403927370885\n",
      "Step =  14400 loss value = 0.027377687055736077\n",
      "Step =  14800 loss value = 0.02625535322110136\n",
      "Step =  15200 loss value = 0.025214048272106326\n",
      "Step =  15600 loss value = 0.024245635106098472\n",
      "Step =  16000 loss value = 0.023343005303226534\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,0,0,1])\n",
    "\n",
    "and_obj=LogicGate('AND',xdata,tdata)\n",
    "\n",
    "and_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a4558d-bce0-4ac0-9f47-f339f9888e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND \n",
      "\n",
      "(array([5.3342101e-05]), 0)\n",
      "(array([0.00602656]), 0)\n",
      "(array([0.00604345]), 0)\n",
      "(array([0.98887882]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(and_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    print(and_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10524c11-8a78-4f8d-bf19-c2d5cfa86735",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORobject is created\n",
      "Initial loss value =  3.0456399526745885\n",
      "Step =  0 loss value = 3.0227606115682626\n",
      "Step =  400 loss value = 2.0937173872515173\n",
      "Step =  800 loss value = 1.9390765614562797\n",
      "Step =  1200 loss value = 1.6685507411056664\n",
      "Step =  1600 loss value = 1.3025403145569077\n",
      "Step =  2000 loss value = 0.9447486040554066\n",
      "Step =  2400 loss value = 0.6680872982168488\n",
      "Step =  2800 loss value = 0.4795408961821296\n",
      "Step =  3200 loss value = 0.35594067884272473\n",
      "Step =  3600 loss value = 0.2740049561538661\n",
      "Step =  4000 loss value = 0.21798096334822703\n",
      "Step =  4400 loss value = 0.17829909172946523\n",
      "Step =  4800 loss value = 0.14923671037177633\n",
      "Step =  5200 loss value = 0.12730978346834995\n",
      "Step =  5600 loss value = 0.11033413280964917\n",
      "Step =  6000 loss value = 0.09689634646722667\n",
      "Step =  6400 loss value = 0.08605333858875179\n",
      "Step =  6800 loss value = 0.07715780164404704\n",
      "Step =  7200 loss value = 0.06975392667405167\n",
      "Step =  7600 loss value = 0.06351329020292762\n",
      "Step =  8000 loss value = 0.05819433176403936\n",
      "Step =  8400 loss value = 0.05361607080364107\n",
      "Step =  8800 loss value = 0.04964064754800631\n",
      "Step =  9200 loss value = 0.046161468748864995\n",
      "Step =  9600 loss value = 0.04309499621580337\n",
      "Step =  10000 loss value = 0.040374953618268775\n",
      "Step =  10400 loss value = 0.037948170313796686\n",
      "Step =  10800 loss value = 0.03577155345505986\n",
      "Step =  11200 loss value = 0.033809850728889874\n",
      "Step =  11600 loss value = 0.032033975661021806\n",
      "Step =  12000 loss value = 0.030419738905608885\n",
      "Step =  12400 loss value = 0.028946876379772314\n",
      "Step =  12800 loss value = 0.027598297094164063\n",
      "Step =  13200 loss value = 0.02635949542688787\n",
      "Step =  13600 loss value = 0.025218087784798445\n",
      "Step =  14000 loss value = 0.024163444280846425\n",
      "Step =  14400 loss value = 0.023186393660562698\n",
      "Step =  14800 loss value = 0.02227898518458297\n",
      "Step =  15200 loss value = 0.02143429515705946\n",
      "Step =  15600 loss value = 0.02064626871666689\n",
      "Step =  16000 loss value = 0.019909589678631136\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,1,1,1])\n",
    "\n",
    "or_obj=LogicGate('OR',xdata,tdata)\n",
    "\n",
    "or_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52b4669f-ec60-4968-bbbc-9932f5709f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR \n",
      "\n",
      "(array([0.01073479]), 0)\n",
      "(array([0.9957972]), 1)\n",
      "(array([0.99541266]), 1)\n",
      "(array([0.99969243]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(or_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    print(or_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5fe680f-1d3f-45e9-8dd9-847e818a4e71",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NANDobject is created\n",
      "Initial loss value =  3.778816113038485\n",
      "Step =  0 loss value = 3.7420888424494003\n",
      "Step =  400 loss value = 2.3626037913118405\n",
      "Step =  800 loss value = 2.2774542923603844\n",
      "Step =  1200 loss value = 2.1567051755907722\n",
      "Step =  1600 loss value = 1.9174499385663482\n",
      "Step =  2000 loss value = 1.5741090930837456\n",
      "Step =  2400 loss value = 1.217607770107021\n",
      "Step =  2800 loss value = 0.9002773095490912\n",
      "Step =  3200 loss value = 0.6554781750768166\n",
      "Step =  3600 loss value = 0.4838813874789877\n",
      "Step =  4000 loss value = 0.36733231841633274\n",
      "Step =  4400 loss value = 0.2874938821120959\n",
      "Step =  4800 loss value = 0.2314212903108448\n",
      "Step =  5200 loss value = 0.19087365316099614\n",
      "Step =  5600 loss value = 0.1607076338526181\n",
      "Step =  6000 loss value = 0.1376770343843208\n",
      "Step =  6400 loss value = 0.1196862980325776\n",
      "Step =  6800 loss value = 0.10534711853895737\n",
      "Step =  7200 loss value = 0.09371556920193673\n",
      "Step =  7600 loss value = 0.08413390023998664\n",
      "Step =  8000 loss value = 0.07613325992628876\n",
      "Step =  8400 loss value = 0.06937245480776963\n",
      "Step =  8800 loss value = 0.06359848114267161\n",
      "Step =  9200 loss value = 0.05862050770161014\n",
      "Step =  9600 loss value = 0.05429235797522379\n",
      "Step =  10000 loss value = 0.05050048004604583\n",
      "Step =  10400 loss value = 0.0471555326865812\n",
      "Step =  10800 loss value = 0.04418640048817285\n",
      "Step =  11200 loss value = 0.04153586993727342\n",
      "Step =  11600 loss value = 0.03915746022285006\n",
      "Step =  12000 loss value = 0.03701306930446227\n",
      "Step =  12400 loss value = 0.03507120386709699\n",
      "Step =  12800 loss value = 0.033305633055691786\n",
      "Step =  13200 loss value = 0.03169435361850496\n",
      "Step =  13600 loss value = 0.03021878654208728\n",
      "Step =  14000 loss value = 0.02886314763387927\n",
      "Step =  14400 loss value = 0.02761395013589822\n",
      "Step =  14800 loss value = 0.026459608503001768\n",
      "Step =  15200 loss value = 0.025390120383872356\n",
      "Step =  15600 loss value = 0.024396809558735126\n",
      "Step =  16000 loss value = 0.023472116763617733\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([1,1,1,0])\n",
    "\n",
    "nand_obj=LogicGate('NAND',xdata,tdata)\n",
    "\n",
    "nand_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "702a738a-a6af-48df-96b1-1ed290b7d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND \n",
      "\n",
      "(array([0.99998114]), 1)\n",
      "(array([0.99421049]), 1)\n",
      "(array([0.99421013]), 1)\n",
      "(array([0.0117708]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(nand_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    print(nand_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "930dedbf-b34d-4fef-8cc3-c37801b4bc1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XORobject is created\n",
      "Initial loss value =  5.410676677432061\n",
      "Step =  0 loss value = 5.288296179590584\n",
      "Step =  400 loss value = 2.7615865429479713\n",
      "Step =  800 loss value = 2.7539112548147053\n",
      "Step =  1200 loss value = 2.742765461345594\n",
      "Step =  1600 loss value = 2.7261633155206386\n",
      "Step =  2000 loss value = 2.7014426616285117\n",
      "Step =  2400 loss value = 2.665263433616955\n",
      "Step =  2800 loss value = 2.613832442758609\n",
      "Step =  3200 loss value = 2.5439040157568575\n",
      "Step =  3600 loss value = 2.4550202600725393\n",
      "Step =  4000 loss value = 2.3513319276950684\n",
      "Step =  4400 loss value = 2.2398897541312426\n",
      "Step =  4800 loss value = 2.1263845605955263\n",
      "Step =  5200 loss value = 2.012650685099489\n",
      "Step =  5600 loss value = 1.8970965459661564\n",
      "Step =  6000 loss value = 1.7764222447233422\n",
      "Step =  6400 loss value = 1.6475072669523942\n",
      "Step =  6800 loss value = 1.509090330337402\n",
      "Step =  7200 loss value = 1.3627230764417195\n",
      "Step =  7600 loss value = 1.2126063864518848\n",
      "Step =  8000 loss value = 1.0645706296928479\n",
      "Step =  8400 loss value = 0.9246710307431074\n",
      "Step =  8800 loss value = 0.7977976609566559\n",
      "Step =  9200 loss value = 0.6867980474375174\n",
      "Step =  9600 loss value = 0.5923601938734141\n",
      "Step =  10000 loss value = 0.513488635960289\n",
      "Step =  10400 loss value = 0.44823504222476307\n",
      "Step =  10800 loss value = 0.3943579390016063\n",
      "Step =  11200 loss value = 0.3497390105076113\n",
      "Step =  11600 loss value = 0.31256405726627123\n",
      "Step =  12000 loss value = 0.28135694335183453\n",
      "Step =  12400 loss value = 0.25494648253643254\n",
      "Step =  12800 loss value = 0.2324130055499602\n",
      "Step =  13200 loss value = 0.21303569498190306\n",
      "Step =  13600 loss value = 0.19624794086833575\n",
      "Step =  14000 loss value = 0.18160187603257497\n",
      "Step =  14400 loss value = 0.16874103955252928\n",
      "Step =  14800 loss value = 0.1573795794570829\n",
      "Step =  15200 loss value = 0.1472864932460211\n",
      "Step =  15600 loss value = 0.13827367257769269\n",
      "Step =  16000 loss value = 0.1301867973497946\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,1,1,0])\n",
    "\n",
    "xor_obj=LogicGate('XOR',xdata,tdata)\n",
    "\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57be0f0e-9056-4fa1-b51d-380d7b3f963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR \n",
      "\n",
      "(array([0.03278547]), 0)\n",
      "(array([0.96611821]), 1)\n",
      "(array([0.97259126]), 1)\n",
      "(array([0.03400035]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(xor_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    print(xor_obj.predict(data))\n",
    "    \n",
    "# 학습량이 부족하면 다른 값이 나올 수 있음 8000 -> 16000으로 증가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
