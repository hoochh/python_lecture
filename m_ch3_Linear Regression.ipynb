{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f988282-0c54-4c0f-bcba-bde71fb2caf4",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6a0ae8-c282-4dc9-96b0-ea21e90e4a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape = (5, 1) t_data.shape = (5, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([2,3,4,5,6]).reshape(5,1)\n",
    "\n",
    "#raw_data = [[1,2],[2,3],[3,4],[4,5],[5,6]]\n",
    "#Y=X+1\n",
    "\n",
    "print(\"x_data.shape =\", x_data.shape, \"t_data.shape =\", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23c8c5b-a561-4b64-9eff-204fcdf89fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W=  [[0.44214605]] , W.shape =  (1, 1) b=  [0.50792443] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(1,1) #2차원배열\n",
    "b=np.random.rand(1)\n",
    "print(\"W= \",W,\", W.shape = \", W.shape, \"b= \",b,\", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e14de0a-4695-4d02-9f60-665b408b108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2)/(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c381a8-00fb-4c05-aca3-83e833b598c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x= 1e-4\n",
    "    grad=np.zeros_like(x) \n",
    "    # 수치미분 결과를 grad에 저장\n",
    "    # x와 똑같은 shape을 가진 배열(혹은 행렬) 생성 (요소값은 0임)\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #모든 입력변수에 대해 편미분하기 위해 iterator 획득\n",
    "    # iterator 하나 생성. 플래그는 멀티 인덱스 설정\n",
    "    # 멀티 인덱스를 설정하면 다차원 배열이라도 \n",
    "    # 순차적으로 interator 생성 후 값을 꺼낼 수 있음\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        \n",
    "        tmp_val=x[idx] \n",
    "        # 임시 변수로 x[idx] 의 원값을 저장\n",
    "        # numpy 타입은 mutable 이므로 원래 값 보관\n",
    "        \n",
    "        x[idx]=float(tmp_val)+delta_x # 전향 차분\n",
    "        fx1=f(x) #f(x+delta_x) # 첫번째 인자로 들어온 함수를 대입\n",
    "        \n",
    "        x[idx]=tmp_val-delta_x # 후향 차분\n",
    "        fx2=f(x) #f(x-delta_x) # 첫번째 인자로 들어온 함수를 다시 대입\n",
    "        \n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x) # 미분 결과를 grad에...\n",
    "        \n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32713fc-1507-453a-b16c-cef6e1c6a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2)/(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5fdcf1-2025-4464-aa3e-924f1c6fd2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy type\n",
    "def predict(x):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c718fa40-2080-41f6-ab5c-6db8e56cd479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  5.3123874604369 Initial W =  [[0.44214605]] \n",
      " , b =  [0.50792443]\n",
      "step =  0 error value =  3.1336540288247376 W =  [[0.59439845]] , b =  [0.54210204]\n",
      "step =  400 error value =  0.0014173174846548774 W =  [[1.02444727]] , b =  [0.91175921]\n",
      "step =  800 error value =  9.043323466344874e-05 W =  [[1.00617534]] , b =  [0.97771053]\n",
      "step =  1200 error value =  5.770175010355223e-06 W =  [[1.00155988]] , b =  [0.99436972]\n",
      "step =  1600 error value =  3.681712787782914e-07 W =  [[1.00039402]] , b =  [0.9985778]\n",
      "step =  2000 error value =  2.3491504204557577e-08 W =  [[1.00009953]] , b =  [0.99964075]\n",
      "step =  2400 error value =  1.4988968493804216e-09 W =  [[1.00002514]] , b =  [0.99990926]\n",
      "step =  2800 error value =  9.563848042595962e-11 W =  [[1.00000635]] , b =  [0.99997708]\n",
      "step =  3200 error value =  6.102300463685043e-12 W =  [[1.0000016]] , b =  [0.99999421]\n",
      "step =  3600 error value =  3.8936284638853045e-13 W =  [[1.00000041]] , b =  [0.99999854]\n",
      "step =  4000 error value =  2.4843651513956736e-14 W =  [[1.0000001]] , b =  [0.99999963]\n",
      "step =  4400 error value =  1.5851718744910703e-15 W =  [[1.00000003]] , b =  [0.99999991]\n",
      "step =  4800 error value =  1.0114333917461177e-16 W =  [[1.00000001]] , b =  [0.99999998]\n",
      "step =  5200 error value =  6.453543571491751e-18 W =  [[1.]] , b =  [0.99999999]\n",
      "step =  5600 error value =  4.117739475841538e-19 W =  [[1.]] , b =  [1.]\n",
      "step =  6000 error value =  2.6273571135968855e-20 W =  [[1.]] , b =  [1.]\n",
      "step =  6400 error value =  1.6764326427703254e-21 W =  [[1.]] , b =  [1.]\n",
      "step =  6800 error value =  1.0696557211867947e-22 W =  [[1.]] , b =  [1.]\n",
      "step =  7200 error value =  6.827643081178466e-24 W =  [[1.]] , b =  [1.]\n",
      "step =  7600 error value =  4.363941451220092e-25 W =  [[1.]] , b =  [1.]\n",
      "step =  8000 error value =  2.8001643349996604e-26 W =  [[1.]] , b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2 # 발산하는 경우, 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f=lambda x: loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data,t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(8001):\n",
    "    W -= learning_rate * numerical_derivative(f,W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data,t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add5a9fc-7e9a-475a-b7b1-a51149052cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f60907-5ff2-48d6-83c9-82a21dacb53a",
   "metadata": {},
   "source": [
    "# Multi-variable regression\n",
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d823dd70-a25f-43f3-bcff-8ccc1b79a47c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73.  80.  75. 152.]\n",
      " [ 93.  88.  93. 185.]\n",
      " [ 89.  91.  90. 180.]\n",
      " [ 96.  98. 100. 196.]\n",
      " [ 73.  66.  70. 142.]\n",
      " [ 53.  46.  55. 101.]\n",
      " [ 69.  74.  77. 149.]\n",
      " [ 47.  56.  60. 115.]\n",
      " [ 87.  79.  90. 175.]\n",
      " [ 79.  70.  88. 164.]\n",
      " [ 69.  70.  73. 141.]\n",
      " [ 70.  65.  74. 141.]\n",
      " [ 93.  95.  91. 184.]\n",
      " [ 79.  80.  73. 152.]\n",
      " [ 70.  73.  78. 148.]\n",
      " [ 93.  89.  96. 192.]\n",
      " [ 78.  75.  68. 147.]\n",
      " [ 81.  90.  93. 183.]\n",
      " [ 88.  92.  86. 177.]\n",
      " [ 78.  83.  77. 159.]\n",
      " [ 82.  86.  90. 177.]\n",
      " [ 86.  82.  89. 175.]\n",
      " [ 78.  83.  85. 175.]\n",
      " [ 76.  83.  71. 149.]\n",
      " [ 96.  93.  95. 192.]]\n",
      "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
      "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_data=np.loadtxt('data/data-01-test-score.csv', delimiter=',',dtype=np.float32)\n",
    "\n",
    "print(loaded_data)\n",
    "x_data=loaded_data[:,0:-1]\n",
    "t_data=loaded_data[:,[-1]]\n",
    "\n",
    "#데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "128681e1-83ea-4a92-9499-aae78238c0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.45625837]\n",
      " [0.58824675]\n",
      " [0.45249258]] , W.shape =  (3, 1) , b = [0.20734241] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(3,1) # 3X1 행렬\n",
    "b=np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b =\", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acf64f3d-a1c5-4ad7-baa2-777091a4a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2)/(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db55e8e2-bb7b-44d1-80c7-13ec9351baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x= 1e-4\n",
    "    grad=np.zeros_like(x) \n",
    "    # 수치미분 결과를 grad에 저장\n",
    "    # x와 똑같은 shape을 가진 배열(혹은 행렬) 생성 (요소값은 0임)\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #모든 입력변수에 대해 편미분하기 위해 iterator 획득\n",
    "    # iterator 하나 생성. 플래그는 멀티 인덱스 설정\n",
    "    # 멀티 인덱스를 설정하면 다차원 배열이라도 \n",
    "    # 순차적으로 interator 생성 후 값을 꺼낼 수 있음\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        \n",
    "        tmp_val=x[idx] \n",
    "        # 임시 변수로 x[idx] 의 원값을 저장\n",
    "        # numpy 타입은 mutable 이므로 원래 값 보관\n",
    "        \n",
    "        x[idx]=float(tmp_val)+delta_x # 전향 차분\n",
    "        fx1=f(x) #f(x+delta_x) # 첫번째 인자로 들어온 함수를 대입\n",
    "        \n",
    "        x[idx]=tmp_val-delta_x # 후향 차분\n",
    "        fx2=f(x) #f(x-delta_x) # 첫번째 인자로 들어온 함수를 다시 대입\n",
    "        \n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x) # 미분 결과를 grad에...\n",
    "        \n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd18dd62-6ba3-4aaf-a1e6-209d6cd4ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x,t):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2)/(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6597282-3934-4679-b7fe-672781e20d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    y=np.dot(x,W)+b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74def7dd-c3de-4770-8808-b0758f3b289e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  1827.45102105688 Initial W =  [[0.45625837]\n",
      " [0.58824675]\n",
      " [0.45249258]] \n",
      " , b =  [0.20734241]\n",
      "step =  0 error value =  684.1891634123369 W =  [[0.52424299]\n",
      " [0.65654902]\n",
      " [0.52271786]] , b =  [0.20785486]\n",
      "step =  400 error value =  11.44245590498413 W =  [[0.60228802]\n",
      " [0.71570859]\n",
      " [0.7040618 ]] , b =  [0.20849359]\n",
      "step =  800 error value =  9.968174570267127 W =  [[0.57761088]\n",
      " [0.67722224]\n",
      " [0.76565653]] , b =  [0.20825748]\n",
      "step =  1200 error value =  8.9144848027519 W =  [[0.55548455]\n",
      " [0.64578587]\n",
      " [0.81788374]] , b =  [0.20795407]\n",
      "step =  1600 error value =  8.159238280336705 W =  [[0.53563325]\n",
      " [0.62017672]\n",
      " [0.86220623]] , b =  [0.20759353]\n",
      "step =  2000 error value =  7.616169617367773 W =  [[0.51781281]\n",
      " [0.59937831]\n",
      " [0.89985451]] , b =  [0.20718447]\n",
      "step =  2400 error value =  7.2242789063913095 W =  [[0.50180681]\n",
      " [0.58254615]\n",
      " [0.93186404]] , b =  [0.20673415]\n",
      "step =  2800 error value =  6.940369961482612 W =  [[0.48742322]\n",
      " [0.5689791 ]\n",
      " [0.95910654]] , b =  [0.20624874]\n",
      "step =  3200 error value =  6.733803749702466 W =  [[0.47449143]\n",
      " [0.5580955 ]\n",
      " [0.98231617]] , b =  [0.20573341]\n",
      "step =  3600 error value =  6.582807275366174 W =  [[0.46285972]\n",
      " [0.54941319]\n",
      " [1.00211151]] , b =  [0.20519259]\n",
      "step =  4000 error value =  6.471875051568052 W =  [[0.45239301]\n",
      " [0.54253281]\n",
      " [1.01901401]] , b =  [0.20462999]\n",
      "step =  4400 error value =  6.389938345695312 W =  [[0.44297095]\n",
      " [0.53712398]\n",
      " [1.03346349]] , b =  [0.2040488]\n",
      "step =  4800 error value =  6.329074205747064 W =  [[0.43448616]\n",
      " [0.53291362]\n",
      " [1.04583109]] , b =  [0.20345169]\n",
      "step =  5200 error value =  6.283594187429291 W =  [[0.42684281]\n",
      " [0.52967632]\n",
      " [1.05643022]] , b =  [0.20284096]\n",
      "step =  5600 error value =  6.249400347305877 W =  [[0.41995526]\n",
      " [0.52722627]\n",
      " [1.06552566]] , b =  [0.20221854]\n",
      "step =  6000 error value =  6.223529500406606 W =  [[0.41374694]\n",
      " [0.52541053]\n",
      " [1.07334126]] , b =  [0.2015861]\n",
      "step =  6400 error value =  6.203830206711911 W =  [[0.4081493 ]\n",
      " [0.5241034 ]\n",
      " [1.08006644]] , b =  [0.20094503]\n",
      "step =  6800 error value =  6.188733425905463 W =  [[0.40310097]\n",
      " [0.52320181]\n",
      " [1.08586155]] , b =  [0.20029655]\n",
      "step =  7200 error value =  6.177089350318381 W =  [[0.39854696]\n",
      " [0.52262141]\n",
      " [1.09086247]] , b =  [0.19964169]\n",
      "step =  7600 error value =  6.168051055193416 W =  [[0.39443795]\n",
      " [0.5222933 ]\n",
      " [1.09518443]] , b =  [0.19898132]\n",
      "step =  8000 error value =  6.160991319350279 W =  [[0.39072967]\n",
      " [0.52216142]\n",
      " [1.09892524]] , b =  [0.19831619]\n",
      "step =  8400 error value =  6.155442987703186 W =  [[0.38738241]\n",
      " [0.52218025]\n",
      " [1.10216797]] , b =  [0.19764696]\n",
      "step =  8800 error value =  6.151056074715559 W =  [[0.38436046]\n",
      " [0.52231296]\n",
      " [1.10498329]] , b =  [0.19697417]\n",
      "step =  9200 error value =  6.1475667990061345 W =  [[0.38163177]\n",
      " [0.52252991]\n",
      " [1.10743133]] , b =  [0.1962983]\n",
      "step =  9600 error value =  6.144775142535312 W =  [[0.37916748]\n",
      " [0.52280734]\n",
      " [1.10956335]] , b =  [0.19561977]\n",
      "step =  10000 error value =  6.142528517613052 W =  [[0.37694165]\n",
      " [0.5231263 ]\n",
      " [1.11142304]] , b =  [0.19493893]\n",
      "step =  10400 error value =  6.140709823920954 W =  [[0.37493095]\n",
      " [0.52347181]\n",
      " [1.11304775]] , b =  [0.19425608]\n",
      "step =  10800 error value =  6.139228671910959 W =  [[0.37311435]\n",
      " [0.52383211]\n",
      " [1.11446938]] , b =  [0.19357149]\n",
      "step =  11200 error value =  6.138014898823015 W =  [[0.37147293]\n",
      " [0.52419805]\n",
      " [1.11571527]] , b =  [0.19288538]\n",
      "step =  11600 error value =  6.137013751687823 W =  [[0.36998963]\n",
      " [0.52456263]\n",
      " [1.11680884]] , b =  [0.19219796]\n",
      "step =  12000 error value =  6.136182287965015 W =  [[0.36864909]\n",
      " [0.52492056]\n",
      " [1.11777017]] , b =  [0.1915094]\n",
      "step =  12400 error value =  6.13548666997642 W =  [[0.36743746]\n",
      " [0.52526793]\n",
      " [1.11861656]] , b =  [0.19081984]\n",
      "step =  12800 error value =  6.134900118864858 W =  [[0.36634225]\n",
      " [0.52560195]\n",
      " [1.11936286]] , b =  [0.19012942]\n",
      "step =  13200 error value =  6.134401357904385 W =  [[0.36535219]\n",
      " [0.52592072]\n",
      " [1.12002188]] , b =  [0.18943825]\n",
      "step =  13600 error value =  6.13397342098796 W =  [[0.36445713]\n",
      " [0.52622301]\n",
      " [1.12060468]] , b =  [0.18874644]\n",
      "step =  14000 error value =  6.133602735247449 W =  [[0.36364789]\n",
      " [0.52650819]\n",
      " [1.12112081]] , b =  [0.18805406]\n",
      "step =  14400 error value =  6.1332784107021725 W =  [[0.36291619]\n",
      " [0.526776  ]\n",
      " [1.12157855]] , b =  [0.18736119]\n",
      "step =  14800 error value =  6.132991687210677 W =  [[0.36225458]\n",
      " [0.52702653]\n",
      " [1.12198507]] , b =  [0.18666791]\n",
      "step =  15200 error value =  6.132735501664468 W =  [[0.36165629]\n",
      " [0.52726014]\n",
      " [1.12234659]] , b =  [0.18597427]\n",
      "step =  15600 error value =  6.132504147640417 W =  [[0.36111525]\n",
      " [0.52747732]\n",
      " [1.12266852]] , b =  [0.18528032]\n",
      "step =  16000 error value =  6.1322930065572105 W =  [[0.36062596]\n",
      " [0.52767874]\n",
      " [1.12295558]] , b =  [0.18458611]\n",
      "step =  16400 error value =  6.132098334435811 W =  [[0.36018344]\n",
      " [0.52786512]\n",
      " [1.12321188]] , b =  [0.18389168]\n",
      "step =  16800 error value =  6.131917092126065 W =  [[0.35978321]\n",
      " [0.52803725]\n",
      " [1.123441  ]] , b =  [0.18319706]\n",
      "step =  17200 error value =  6.131746809677911 W =  [[0.35942122]\n",
      " [0.52819596]\n",
      " [1.12364609]] , b =  [0.18250229]\n",
      "step =  17600 error value =  6.131585477658813 W =  [[0.35909379]\n",
      " [0.52834206]\n",
      " [1.1238299 ]] , b =  [0.18180739]\n",
      "step =  18000 error value =  6.131431459823692 W =  [[0.35879762]\n",
      " [0.52847638]\n",
      " [1.12399484]] , b =  [0.18111239]\n",
      "step =  18400 error value =  6.131283422772986 W =  [[0.35852972]\n",
      " [0.52859973]\n",
      " [1.12414303]] , b =  [0.18041731]\n",
      "step =  18800 error value =  6.1311402791709035 W =  [[0.35828739]\n",
      " [0.52871289]\n",
      " [1.12427634]] , b =  [0.17972217]\n",
      "step =  19200 error value =  6.131001141823856 W =  [[0.35806817]\n",
      " [0.5288166 ]\n",
      " [1.12439641]] , b =  [0.17902699]\n",
      "step =  19600 error value =  6.130865286479451 W =  [[0.35786986]\n",
      " [0.52891158]\n",
      " [1.1245047 ]] , b =  [0.17833178]\n",
      "step =  20000 error value =  6.1307321216467985 W =  [[0.35769046]\n",
      " [0.52899851]\n",
      " [1.12460247]] , b =  [0.17763656]\n",
      "step =  20400 error value =  6.130601164081257 W =  [[0.35752816]\n",
      " [0.52907802]\n",
      " [1.12469088]] , b =  [0.17694134]\n",
      "step =  20800 error value =  6.130472018849169 W =  [[0.35738133]\n",
      " [0.52915071]\n",
      " [1.12477092]] , b =  [0.17624612]\n",
      "step =  21200 error value =  6.130344363100994 W =  [[0.3572485 ]\n",
      " [0.52921713]\n",
      " [1.12484347]] , b =  [0.17555093]\n",
      "step =  21600 error value =  6.130217932852082 W =  [[0.35712832]\n",
      " [0.52927782]\n",
      " [1.12490934]] , b =  [0.17485577]\n",
      "step =  22000 error value =  6.13009251220626 W =  [[0.35701959]\n",
      " [0.52933324]\n",
      " [1.12496921]] , b =  [0.17416064]\n",
      "step =  22400 error value =  6.129967924565017 W =  [[0.35692122]\n",
      " [0.52938385]\n",
      " [1.12502373]] , b =  [0.17346556]\n",
      "step =  22800 error value =  6.129844025452692 W =  [[0.35683222]\n",
      " [0.52943006]\n",
      " [1.12507344]] , b =  [0.17277053]\n",
      "step =  23200 error value =  6.129720696658126 W =  [[0.3567517 ]\n",
      " [0.52947225]\n",
      " [1.12511883]] , b =  [0.17207555]\n",
      "step =  23600 error value =  6.1295978414491525 W =  [[0.35667884]\n",
      " [0.52951077]\n",
      " [1.12516036]] , b =  [0.17138063]\n",
      "step =  24000 error value =  6.129475380661978 W =  [[0.35661292]\n",
      " [0.52954595]\n",
      " [1.12519841]] , b =  [0.17068578]\n",
      "step =  24400 error value =  6.129353249505028 W =  [[0.35655328]\n",
      " [0.52957808]\n",
      " [1.12523335]] , b =  [0.169991]\n",
      "step =  24800 error value =  6.129231394945537 W =  [[0.35649932]\n",
      " [0.52960744]\n",
      " [1.12526547]] , b =  [0.16929629]\n",
      "step =  25200 error value =  6.12910977357276 W =  [[0.35645049]\n",
      " [0.52963426]\n",
      " [1.12529508]] , b =  [0.16860166]\n",
      "step =  25600 error value =  6.128988349849807 W =  [[0.35640631]\n",
      " [0.52965879]\n",
      " [1.12532241]] , b =  [0.16790711]\n",
      "step =  26000 error value =  6.128867094684016 W =  [[0.35636634]\n",
      " [0.52968122]\n",
      " [1.1253477 ]] , b =  [0.16721264]\n",
      "step =  26400 error value =  6.128745984257057 W =  [[0.35633017]\n",
      " [0.52970175]\n",
      " [1.12537115]] , b =  [0.16651826]\n",
      "step =  26800 error value =  6.128624999067776 W =  [[0.35629744]\n",
      " [0.52972055]\n",
      " [1.12539295]] , b =  [0.16582396]\n",
      "step =  27200 error value =  6.128504123148831 W =  [[0.35626782]\n",
      " [0.52973778]\n",
      " [1.12541325]] , b =  [0.16512975]\n",
      "step =  27600 error value =  6.128383343425645 W =  [[0.35624103]\n",
      " [0.52975358]\n",
      " [1.12543221]] , b =  [0.16443563]\n",
      "step =  28000 error value =  6.128262649191804 W =  [[0.35621678]\n",
      " [0.52976809]\n",
      " [1.12544995]] , b =  [0.16374161]\n",
      "step =  28400 error value =  6.128142031679527 W =  [[0.35619484]\n",
      " [0.52978142]\n",
      " [1.1254666 ]] , b =  [0.16304767]\n",
      "step =  28800 error value =  6.128021483708219 W =  [[0.35617499]\n",
      " [0.52979369]\n",
      " [1.12548226]] , b =  [0.16235383]\n",
      "step =  29200 error value =  6.127900999396656 W =  [[0.35615702]\n",
      " [0.52980498]\n",
      " [1.12549704]] , b =  [0.16166009]\n",
      "step =  29600 error value =  6.127780573927474 W =  [[0.35614077]\n",
      " [0.5298154 ]\n",
      " [1.12551101]] , b =  [0.16096645]\n",
      "step =  30000 error value =  6.127660203354217 W =  [[0.35612606]\n",
      " [0.52982502]\n",
      " [1.12552425]] , b =  [0.1602729]\n",
      "step =  30400 error value =  6.127539884443625 W =  [[0.35611275]\n",
      " [0.52983392]\n",
      " [1.12553684]] , b =  [0.15957945]\n",
      "step =  30800 error value =  6.1274196145462785 W =  [[0.3561007 ]\n",
      " [0.52984217]\n",
      " [1.12554884]] , b =  [0.1588861]\n",
      "step =  31200 error value =  6.127299391490785 W =  [[0.3560898 ]\n",
      " [0.52984982]\n",
      " [1.12556031]] , b =  [0.15819286]\n",
      "step =  31600 error value =  6.127179213497152 W =  [[0.35607994]\n",
      " [0.52985693]\n",
      " [1.12557129]] , b =  [0.15749971]\n",
      "step =  32000 error value =  6.1270590791059 W =  [[0.35607101]\n",
      " [0.52986355]\n",
      " [1.12558184]] , b =  [0.15680666]\n",
      "step =  32400 error value =  6.126938987119919 W =  [[0.35606293]\n",
      " [0.52986973]\n",
      " [1.12559199]] , b =  [0.15611372]\n",
      "step =  32800 error value =  6.126818936556959 W =  [[0.35605563]\n",
      " [0.52987551]\n",
      " [1.12560179]] , b =  [0.15542088]\n",
      "step =  33200 error value =  6.126698926610689 W =  [[0.35604901]\n",
      " [0.52988093]\n",
      " [1.12561126]] , b =  [0.15472814]\n",
      "step =  33600 error value =  6.1265789566188 W =  [[0.35604302]\n",
      " [0.52988602]\n",
      " [1.12562045]] , b =  [0.15403551]\n",
      "step =  34000 error value =  6.126459026036901 W =  [[0.35603761]\n",
      " [0.52989081]\n",
      " [1.12562937]] , b =  [0.15334297]\n",
      "step =  34400 error value =  6.126339134417265 W =  [[0.3560327 ]\n",
      " [0.52989533]\n",
      " [1.12563805]] , b =  [0.15265055]\n",
      "step =  34800 error value =  6.126219281391127 W =  [[0.35602827]\n",
      " [0.52989961]\n",
      " [1.12564652]] , b =  [0.15195822]\n",
      "step =  35200 error value =  6.126099466654532 W =  [[0.35602425]\n",
      " [0.52990367]\n",
      " [1.1256548 ]] , b =  [0.151266]\n",
      "step =  35600 error value =  6.125979689956495 W =  [[0.35602062]\n",
      " [0.52990752]\n",
      " [1.1256629 ]] , b =  [0.15057389]\n",
      "step =  36000 error value =  6.125859951089504 W =  [[0.35601733]\n",
      " [0.5299112 ]\n",
      " [1.12567083]] , b =  [0.14988188]\n",
      "step =  36400 error value =  6.125740249881506 W =  [[0.35601435]\n",
      " [0.52991471]\n",
      " [1.12567863]] , b =  [0.14918997]\n",
      "step =  36800 error value =  6.12562058618965 W =  [[0.35601166]\n",
      " [0.52991807]\n",
      " [1.1256863 ]] , b =  [0.14849817]\n",
      "step =  37200 error value =  6.125500959894807 W =  [[0.35600922]\n",
      " [0.52992129]\n",
      " [1.12569384]] , b =  [0.14780648]\n",
      "step =  37600 error value =  6.125381370897469 W =  [[0.35600701]\n",
      " [0.52992439]\n",
      " [1.12570128]] , b =  [0.14711489]\n",
      "step =  38000 error value =  6.1252618191140265 W =  [[0.35600501]\n",
      " [0.52992739]\n",
      " [1.12570863]] , b =  [0.14642341]\n",
      "step =  38400 error value =  6.1251423044739965 W =  [[0.3560032 ]\n",
      " [0.52993028]\n",
      " [1.12571588]] , b =  [0.14573203]\n",
      "step =  38800 error value =  6.1250228269175855 W =  [[0.35600156]\n",
      " [0.52993308]\n",
      " [1.12572306]] , b =  [0.14504076]\n",
      "step =  39200 error value =  6.124903386393782 W =  [[0.35600008]\n",
      " [0.5299358 ]\n",
      " [1.12573017]] , b =  [0.14434959]\n",
      "step =  39600 error value =  6.124783982858805 W =  [[0.35599874]\n",
      " [0.52993845]\n",
      " [1.12573721]] , b =  [0.14365853]\n",
      "step =  40000 error value =  6.124664616274678 W =  [[0.35599752]\n",
      " [0.52994103]\n",
      " [1.12574419]] , b =  [0.14296757]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5 # 발산하는 경우, 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f=lambda x: loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data,t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(40001):\n",
    "    W -= learning_rate * numerical_derivative(f,W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data,t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bfe686d-2af5-4e31-87ac-15bba1fe2398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.86221976])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=np.array([100,98,81])\n",
    "\n",
    "predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
