{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29cde984-ce40-449d-b0b8-561138285f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (9, 2) , t_data.shape =  (9, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data=np.array([[2,4],[4,11],[6,6],[8,5],[10,7],[12,16],[14,8],[16,3],[18,7]]) #(예습시간, 복습시간)\n",
    "t_data=np.array([0,0,0,0,1,1,1,1,1]).reshape(9,1) # 1 (Pass), 0(Fail)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c4cd7e-1240-4f77-9bdc-395e5123a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.96381378]\n",
      " [0.45202906]] , W.shape =  (2, 1) b =  [0.77410662] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(2,1) # 2*1 정렬\n",
    "b=np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \"b = \", b, \", b.shape = \", b.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bfa2e53-c2c0-4da5-9a7d-d7fe57c85a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종출력은 y=sigmoid(Wx+b) 이며, 손실함수는 cross-entropy 로 나타냄\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def loss_func(x,t):\n",
    "    delta=1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5942cc-be42-4dde-a02f-11c0b00608b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x= 1e-4\n",
    "    grad=np.zeros_like(x) \n",
    "    # 수치미분 결과를 grad에 저장\n",
    "    # x와 똑같은 shape을 가진 배열(혹은 행렬) 생성 (요소값은 0임)\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #모든 입력변수에 대해 편미분하기 위해 iterator 획득\n",
    "    # iterator 하나 생성. 플래그는 멀티 인덱스 설정\n",
    "    # 멀티 인덱스를 설정하면 다차원 배열이라도 \n",
    "    # 순차적으로 interator 생성 후 값을 꺼낼 수 있음\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        \n",
    "        tmp_val=x[idx] \n",
    "        # 임시 변수로 x[idx] 의 원값을 저장\n",
    "        # numpy 타입은 mutable 이므로 원래 값 보관\n",
    "        \n",
    "        x[idx]=float(tmp_val)+delta_x # 전향 차분\n",
    "        fx1=f(x) #f(x+delta_x) # 첫번째 인자로 들어온 함수를 대입\n",
    "        \n",
    "        x[idx]=tmp_val-delta_x # 후향 차분\n",
    "        fx2=f(x) #f(x-delta_x) # 첫번째 인자로 들어온 함수를 다시 대입\n",
    "        \n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x) # 미분 결과를 grad에...\n",
    "        \n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a993da-b2d8-4ca7-928e-1a7fe525f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x,t):\n",
    "    delta=1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    return -np.sum(t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))\n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    if y>=0.5:\n",
    "        result=1 #True\n",
    "    else:\n",
    "        result=0 #False\n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec41b53-2d66-44a0-a5b2-8069d2765725",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  34.129406538433884 Initial W =  [[0.96381378]\n",
      " [0.45202906]] \n",
      " ,b= [0.77410662]\n",
      "step =  0 error value =  23.296674341626943 W =  [[0.76453381]\n",
      " [0.19293577]] ,b =  [0.73459693]\n",
      "step =  400 error value =  2.317148116973726 W =  [[ 0.41488189]\n",
      " [-0.09031715]] ,b =  [-2.5397229]\n",
      "step =  800 error value =  1.6081490020131783 W =  [[ 0.53236068]\n",
      " [-0.02814226]] ,b =  [-4.21062904]\n",
      "step =  1200 error value =  1.2889866523591706 W =  [[0.62033231]\n",
      " [0.00785464]] ,b =  [-5.33646672]\n",
      "step =  1600 error value =  1.1038804365300998 W =  [[0.6911888 ]\n",
      " [0.03334727]] ,b =  [-6.19482779]\n",
      "step =  2000 error value =  0.9806605321491261 W =  [[0.75082897]\n",
      " [0.05357409]] ,b =  [-6.89538182]\n",
      "step =  2400 error value =  0.8912514674713876 W =  [[0.802491  ]\n",
      " [0.07084029]] ,b =  [-7.49217579]\n",
      "step =  2800 error value =  0.8224609153502669 W =  [[0.84814582]\n",
      " [0.08633189]] ,b =  [-8.01564855]\n",
      "step =  3200 error value =  0.7672592125238024 W =  [[0.88908636]\n",
      " [0.10072212]] ,b =  [-8.48455993]\n",
      "step =  3600 error value =  0.7215461990759011 W =  [[0.92621037]\n",
      " [0.11441837]] ,b =  [-8.91125454]\n",
      "step =  4000 error value =  0.6827614173852382 W =  [[0.96017006]\n",
      " [0.12767691]] ,b =  [-9.30427153]\n",
      "step =  4400 error value =  0.6492182078405556 W =  [[0.9914573 ]\n",
      " [0.14066174]] ,b =  [-9.66975491]\n",
      "step =  4800 error value =  0.6197568425366468 W =  [[1.02045497]\n",
      " [0.15347705]] ,b =  [-10.01226814]\n",
      "step =  5200 error value =  0.5935514023170043 W =  [[1.0474694 ]\n",
      " [0.16618655]] ,b =  [-10.33529052]\n",
      "step =  5600 error value =  0.5699962332556977 W =  [[1.07275138]\n",
      " [0.17882572]] ,b =  [-10.64153326]\n",
      "step =  6000 error value =  0.5486360844998828 W =  [[1.09651025]\n",
      " [0.19141009]] ,b =  [-10.93314842]\n",
      "step =  6400 error value =  0.5291214313235815 W =  [[1.11892344]\n",
      " [0.20394121]] ,b =  [-11.21187153]\n",
      "step =  6800 error value =  0.5111789406223882 W =  [[1.14014311]\n",
      " [0.21641116]] ,b =  [-11.47912161]\n",
      "step =  7200 error value =  0.4945913769919412 W =  [[1.1603008 ]\n",
      " [0.22880601]] ,b =  [-11.73607306]\n",
      "step =  7600 error value =  0.47918358479391093 W =  [[1.17951085]\n",
      " [0.2411085 ]] ,b =  [-11.98370856]\n",
      "step =  8000 error value =  0.46481249250979495 W =  [[1.19787288]\n",
      " [0.25330014]] ,b =  [-12.22285853]\n",
      "step =  8400 error value =  0.45135984752888747 W =  [[1.21547385]\n",
      " [0.26536268]] ,b =  [-12.4542312]\n",
      "step =  8800 error value =  0.4387268463695945 W =  [[1.23238961]\n",
      " [0.27727919]] ,b =  [-12.67843581]\n",
      "step =  9200 error value =  0.42683010709451996 W =  [[1.24868635]\n",
      " [0.28903471]] ,b =  [-12.89600063]\n",
      "step =  9600 error value =  0.4155986089779016 W =  [[1.26442176]\n",
      " [0.30061662]] ,b =  [-13.10738727]\n",
      "step =  10000 error value =  0.4049713400367008 W =  [[1.27964613]\n",
      " [0.31201475]] ,b =  [-13.31300196]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-2 # 발산할 때 1e-3~1e-6 값 바꿔 시도\n",
    "\n",
    "f=lambda x: loss_func(x_data,t_data)\n",
    "print(\"Initial error value = \", error_val(x_data,t_data), \"Initial W = \", W, \"\\n\", \",b=\",b)\n",
    "\n",
    "for step in range(10001):\n",
    "    W -= learning_rate * numerical_derivative(f,W)\n",
    "    b -= learning_rate * numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \",b = \", b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
