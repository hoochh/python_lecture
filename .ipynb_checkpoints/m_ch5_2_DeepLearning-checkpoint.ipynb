{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7dbe51c-84ca-4731-b80c-e8bf88e7bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71c785c-0174-40f7-9193-d96d2a8d16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x= 1e-4\n",
    "    grad=np.zeros_like(x) \n",
    "    # 수치미분 결과를 grad에 저장\n",
    "    # x와 똑같은 shape을 가진 배열(혹은 행렬) 생성 (요소값은 0임)\n",
    "    \n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #모든 입력변수에 대해 편미분하기 위해 iterator 획득\n",
    "    # iterator 하나 생성. 플래그는 멀티 인덱스 설정\n",
    "    # 멀티 인덱스를 설정하면 다차원 배열이라도 \n",
    "    # 순차적으로 interator 생성 후 값을 꺼낼 수 있음\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        \n",
    "        tmp_val=x[idx] \n",
    "        # 임시 변수로 x[idx] 의 원값을 저장\n",
    "        # numpy 타입은 mutable 이므로 원래 값 보관\n",
    "        \n",
    "        x[idx]=float(tmp_val)+delta_x # 전향 차분\n",
    "        fx1=f(x) #f(x+delta_x) # 첫번째 인자로 들어온 함수를 대입\n",
    "        \n",
    "        x[idx]=tmp_val-delta_x # 후향 차분\n",
    "        fx2=f(x) #f(x-delta_x) # 첫번째 인자로 들어온 함수를 다시 대입\n",
    "        \n",
    "        grad[idx]=(fx1-fx2)/(2*delta_x) # 미분 결과를 grad에...\n",
    "        \n",
    "        x[idx]=tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02daeb6e-a076-4196-82aa-1f57748085c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name=gate_name\n",
    "        \n",
    "        #입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata=xdata.reshape(4,2)\n",
    "        self.__tdata=tdata.reshape(4,1)\n",
    "        \n",
    "        #가중치 W, 바이어스 b 초기화\n",
    "        self.__W=np.random.rand(2,1) # weight. 2 X 1 matrix\n",
    "        self.__b=np.random.rand(1)\n",
    "        \n",
    "        #학습을 learning rate 초기화\n",
    "        self.__learning_rate=1e-2\n",
    "    \n",
    "    #손실함수\n",
    "    def __loss_func(self):\n",
    "        \n",
    "        delta=1e-7 #log 무한대 발산 방지\n",
    "        \n",
    "        z=np.dot(self.__xdata, self.__W)+self.__b\n",
    "        sigmoid(z)\n",
    "        \n",
    "        #cross-entropy\n",
    "        return -np.sum(self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y)+delta))\n",
    "    \n",
    "    def error_val(self):\n",
    "        delta=1e-7 # log 무한대 발산 방지\n",
    "\n",
    "        z=np.dot(self.__xdata,self.__W)+self.__b\n",
    "        y=sigmoid(z)\n",
    "\n",
    "        #cross-entropy\n",
    "        return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
    "\n",
    "    def train(self): # 수치미분을 이용하여 손실함수가 최소가 될 때까지 학습하는 함수\n",
    "        f=lambda x: self.__loss_func()\n",
    "        print(\"Initial error value = \", self.error_val())\n",
    "\n",
    "        for step in range(10001):\n",
    "            self.__W -= self.__learning_rate * numerical_derivative(f,self.__W)\n",
    "            self.__b -= self.__learning_rate * numerical_derivative(f,self.__b)\n",
    "\n",
    "            if(step % 400 == 0):\n",
    "                print(\"step = \", step, \"error value = \", error_val())\n",
    "    \n",
    "    def predict(self,input_data):\n",
    "\n",
    "        z=np.dot(input_data, self.__W)+self.__b\n",
    "        y=sigmoid(z)\n",
    "\n",
    "        if y>=0.5:\n",
    "            result=1 #True\n",
    "        else:\n",
    "            result=0 #False\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b0150e-c827-4160-bdf3-dc64120f1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogicGate Class\n",
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        self.name = gate_name\n",
    "        \n",
    "        #입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4, 2) #__xdata에서 언더바 2개 : 밖에서 못 쓰는 것\n",
    "        self.__tdata = tdata.reshape(4, 1) \n",
    "        \n",
    "        #가중치 W, 바이어스 b 초기화\n",
    "        self.__W = np.random.rand(2, 1)\n",
    "        self.__b = np.random.rand(1)\n",
    "        \n",
    "        #학습률 learining rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "    #손실함수\n",
    "    def __loss_func(self):\n",
    "        delta = 1e-7 #Log 무한대 발산 방지\n",
    "    \n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "\n",
    "        #cross-entropy\n",
    "        return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
    "    \n",
    "    #손실값 계산\n",
    "    def error_val(self):\n",
    "        delta = 1e-7\n",
    "\n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "\n",
    "        return -np.sum( self.__tdata * np.log(y + delta) + (1 - self.__tdata) * np.log((1 - y) + delta))\n",
    "    \n",
    "    #수치미분을 이용하여 손실함수가 최소가 될 때까지 학습하는 함수\n",
    "    def train(self):\n",
    "        f = lambda x : self.__loss_func()\n",
    "        print(\"Initial error value = \", self.error_val())\n",
    "        \n",
    "        for step in range(8001):\n",
    "            #gradient decent 하기 위한 작업\n",
    "            self.__W -= self.__learning_rate * numerical_derivative(f, self.__W)\n",
    "            self.__b -= self.__learning_rate * numerical_derivative(f, self.__b)\n",
    "\n",
    "            #error값이 400의 배수인 것 출력\n",
    "            if (step % 400 == 0):\n",
    "                print(\"Step = \", step, \"error value =\", self.error_val())\n",
    "\n",
    "    #미래값 예측\n",
    "    def predict(self, input_data):\n",
    "        z = np.dot(input_data, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "    \n",
    "        if y >= 0.5:\n",
    "            result = 1  #True\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87485197-6295-4b13-af72-9b3458a3b5d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  4.672671186099007\n",
      "Step =  0 error value = 4.615075094791332\n",
      "Step =  400 error value = 1.5812424344542235\n",
      "Step =  800 error value = 1.1649002319720752\n",
      "Step =  1200 error value = 0.9325347846474437\n",
      "Step =  1600 error value = 0.7804832503359533\n",
      "Step =  2000 error value = 0.6717572698796016\n",
      "Step =  2400 error value = 0.5896013298731394\n",
      "Step =  2800 error value = 0.5251367259464671\n",
      "Step =  3200 error value = 0.47313566834030796\n",
      "Step =  3600 error value = 0.43028344543530384\n",
      "Step =  4000 error value = 0.3943609375243724\n",
      "Step =  4400 error value = 0.3638195371973692\n",
      "Step =  4800 error value = 0.33754254005774875\n",
      "Step =  5200 error value = 0.3147029546640755\n",
      "Step =  5600 error value = 0.2946746252484367\n",
      "Step =  6000 error value = 0.27697447273337067\n",
      "Step =  6400 error value = 0.2612237252367799\n",
      "Step =  6800 error value = 0.24712117453191745\n",
      "Step =  7200 error value = 0.23442429133539355\n",
      "Step =  7600 error value = 0.22293561635451326\n",
      "Step =  8000 error value = 0.21249277673275477\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,0,0,1])\n",
    "\n",
    "AND_obj=LogicGate('AND_GATE',xdata,tdata)\n",
    "\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29dbf1b-7dfe-4ff7-8d73-c08b9db23c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND_GATE \n",
      "\n",
      "[0 0] = 0 \n",
      "\n",
      "[0 1] = 0 \n",
      "\n",
      "[1 0] = 0 \n",
      "\n",
      "[1 1] = 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(AND_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, '=', logical_val, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407c6795-2304-47f8-aa22-cae001050849",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  1.7494987285421102\n",
      "Step =  0 error value = 1.74280631744025\n",
      "Step =  400 error value = 1.0230921443844259\n",
      "Step =  800 error value = 0.7546734146416684\n",
      "Step =  1200 error value = 0.5930289969037913\n",
      "Step =  1600 error value = 0.4858446745400044\n",
      "Step =  2000 error value = 0.4099855370090284\n",
      "Step =  2400 error value = 0.3537126093751992\n",
      "Step =  2800 error value = 0.3104519077650851\n",
      "Step =  3200 error value = 0.2762456442655389\n",
      "Step =  3600 error value = 0.24857542513326303\n",
      "Step =  4000 error value = 0.2257666769475871\n",
      "Step =  4400 error value = 0.20666511397144424\n",
      "Step =  4800 error value = 0.19045079146012103\n",
      "Step =  5200 error value = 0.17652618198399952\n",
      "Step =  5600 error value = 0.16444614768091037\n",
      "Step =  6000 error value = 0.1538726543607564\n",
      "Step =  6400 error value = 0.1445446368213439\n",
      "Step =  6800 error value = 0.1362574384659456\n",
      "Step =  7200 error value = 0.12884846994950924\n",
      "Step =  7600 error value = 0.12218700701041957\n",
      "Step =  8000 error value = 0.11616680370275452\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,1,1,1])\n",
    "\n",
    "OR_obj=LogicGate('OR_GATE',xdata,tdata)\n",
    "\n",
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8663ce0-c6d2-4061-beec-9d5ce9c80c54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_GATE \n",
      "\n",
      "[0 0] = 0 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OR_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "    print(input_data, '=', logical_val, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "233887a5-d9a5-47e2-a5ff-0e7f7f3b54c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  2.5606487487391214\n",
      "Step =  0 error value = 2.5534383725081415\n",
      "Step =  400 error value = 1.5150228746350178\n",
      "Step =  800 error value = 1.1313624601806473\n",
      "Step =  1200 error value = 0.9117098273770579\n",
      "Step =  1600 error value = 0.7660404586173053\n",
      "Step =  2000 error value = 0.6610580736866092\n",
      "Step =  2400 error value = 0.5813227681725297\n",
      "Step =  2800 error value = 0.5185286887666662\n",
      "Step =  3200 error value = 0.46773518754333254\n",
      "Step =  3600 error value = 0.4257867466664661\n",
      "Step =  4000 error value = 0.39055931632638047\n",
      "Step =  4400 error value = 0.3605643684559322\n",
      "Step =  4800 error value = 0.33472488598762434\n",
      "Step =  5200 error value = 0.3122410453656671\n",
      "Step =  5600 error value = 0.29250584202365504\n",
      "Step =  6000 error value = 0.27505003335759814\n",
      "Step =  6400 error value = 0.25950505635835974\n",
      "Step =  6800 error value = 0.24557737337728133\n",
      "Step =  7200 error value = 0.23303031109952155\n",
      "Step =  7600 error value = 0.22167094438127471\n",
      "Step =  8000 error value = 0.21134045556681358\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([1,1,1,0])\n",
    "\n",
    "NAND_obj=LogicGate('NAND_GATE',xdata,tdata)\n",
    "\n",
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bcd3c11-1bdd-4083-a497-7ec5e588a961",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND_GATE \n",
      "\n",
      "[0 0] = 1 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(NAND_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "    print(input_data, '=', logical_val, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91aa24cc-7fcf-4361-8749-f605b7a3d36c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  3.2183066427160796\n",
      "Step =  0 error value = 3.206183887277896\n",
      "Step =  400 error value = 2.7751206295416457\n",
      "Step =  800 error value = 2.7731325097557105\n",
      "Step =  1200 error value = 2.772718891406319\n",
      "Step =  1600 error value = 2.7726218842843062\n",
      "Step =  2000 error value = 2.7725971214969927\n",
      "Step =  2400 error value = 2.772590471952803\n",
      "Step =  2800 error value = 2.7725886371140955\n",
      "Step =  3200 error value = 2.772588123801982\n",
      "Step =  3600 error value = 2.77258797922541\n",
      "Step =  4000 error value = 2.7725879383717107\n",
      "Step =  4400 error value = 2.772587926809404\n",
      "Step =  4800 error value = 2.772587923534623\n",
      "Step =  5200 error value = 2.772587922606778\n",
      "Step =  5600 error value = 2.772587922343848\n",
      "Step =  6000 error value = 2.772587922269333\n",
      "Step =  6400 error value = 2.7725879222482144\n",
      "Step =  6800 error value = 2.772587922242229\n",
      "Step =  7200 error value = 2.7725879222405325\n",
      "Step =  7600 error value = 2.7725879222400516\n",
      "Step =  8000 error value = 2.7725879222399152\n"
     ]
    }
   ],
   "source": [
    "xdata=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata=np.array([0,1,1,0])\n",
    "\n",
    "XOR_obj=LogicGate('XOR_GATE',xdata,tdata)\n",
    "\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d49528c4-c43e-4d04-ba81-395c87e071e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR_GATE \n",
      "\n",
      "[0 0] = 1 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(XOR_obj.name, '\\n')\n",
    "\n",
    "test_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print(input_data, '=', logical_val, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def873e5-6646-435c-b97c-4812ad203711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] = 0\n",
      "[0 1] = 1\n",
      "[1 0] = 1\n",
      "[1 1] = 0\n"
     ]
    }
   ],
   "source": [
    "#XOR을 NAND + OR => AND 조합으로 계산함\n",
    "input_data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "s1=[] #NAND 출력\n",
    "s2=[] #OR 출력\n",
    "\n",
    "new_input_data=[] #AND 입력\n",
    "final_output=[] #AND 출력\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    \n",
    "    s1=NAND_obj.predict(input_data[index]) #NAND 출력\n",
    "    s2=OR_obj.predict(input_data[index]) #OR 출력\n",
    "    \n",
    "    new_input_data.append(s1[-1]) # AND 입력\n",
    "    new_input_data.append(s2[-1]) # AND 입력\n",
    "    \n",
    "    (sigmoid_val, logical_val)=AND_obj.predict(np.array(new_input_data))\n",
    "    \n",
    "    final_output.append(logical_val) #AND 출력, 즉 XOR 출력\n",
    "    new_input_data=[] #AND 입력 초기화\n",
    "    \n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index], '=', final_output[index], end='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
