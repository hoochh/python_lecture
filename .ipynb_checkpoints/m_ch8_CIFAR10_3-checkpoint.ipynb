{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f69bcab-f46d-43af-824c-d847090e5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # 모델을 중간에 끝낼 때\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabd0233-eb92-43c0-a7ba-a1029e9f6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=ImageDataGenerator(rotation_range=20, # 회전\n",
    "                      shear_range=0.2, # 기울임\n",
    "                      width_shift_range=0.2, # 이동\n",
    "                      height_shift_range=0.2,\n",
    "                      horizontal_flip=True) # 좌우반전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900fd024-1f45-46d5-8a22-0b805becc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 데이터셋을 읽고 신경망에 입력할 형태로 변환\n",
    "(x_train, y_train), (x_test, y_test)=cifar10.load_data()\n",
    "\n",
    "x_train=x_train.astype(np.float32) /255.0 #0~1 정규화\n",
    "x_test=x_test.astype(np.float32) /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1688749c-dfc8-4d87-9034-e54e920fbf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000\n",
      "(75000, 32, 32, 3) (75000, 1)\n",
      "(75000, 32, 32, 3) (75000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 보강할 학습데이터 이미지 생성\n",
    "\n",
    "augment_ratio=1.5 # 전체 데이터의 150%를 보강 데이터로 만들 것\n",
    "augment_size=int(augment_ratio * x_train.shape[0]) #x_train.shape[0] : 이미지 개수\n",
    "\n",
    "print(augment_size)\n",
    "\n",
    "# 전체 x_train 개수의 150% 비율만큼\n",
    "randidx=np.random.randint(x_train.shape[0], size=augment_size)\n",
    "\n",
    "# 임의로 선택된 데이터는 원본데이터를 참조하기 때문에\n",
    "# 원본데이터에 영향을 줄 수 있음. 그래서 copy() 함수를 통해 안전하게 복사본 만듬\n",
    "x_augmented=x_train[randidx].copy()\n",
    "y_augmented=y_train[randidx].copy()\n",
    "\n",
    "print(x_augmented.shape, y_augmented.shape)\n",
    "\n",
    "# 이미지 보강 실행\n",
    "x_augmented,y_augmented=gen.flow(x_augmented,y_augmented,\n",
    "                                batch_size=augment_size, \n",
    "                                shuffle=True).next()\n",
    "\n",
    "print(x_augmented.shape, y_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f357cc-b5b8-4c5a-9c45-ac19f3a12a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 32, 32, 3) (125000, 1)\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train에 보강된 데이터 추가\n",
    "x_train=np.concatenate((x_train,x_augmented))\n",
    "y_train=np.concatenate((y_train,y_augmented))\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43661c0-981b-42aa-90de-a93b0b9ad112",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567,082\n",
      "Trainable params: 567,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델 구축\n",
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Conv2D(32,(3,3),activation='relu',padding='same', input_shape=(32,32,3)))\n",
    "cnn.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(128,activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(10,activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41c081-5cc2-4cfd-8330-9cee3c5bef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "489/489 [==============================] - 287s 585ms/step - loss: 1.7270 - accuracy: 0.3556 - val_loss: 1.2828 - val_accuracy: 0.5296\n",
      "Epoch 2/250\n",
      "489/489 [==============================] - 295s 604ms/step - loss: 1.3071 - accuracy: 0.5326 - val_loss: 1.0555 - val_accuracy: 0.6227\n",
      "Epoch 3/250\n",
      "489/489 [==============================] - 296s 606ms/step - loss: 1.1416 - accuracy: 0.5981 - val_loss: 0.9236 - val_accuracy: 0.6691\n",
      "Epoch 4/250\n",
      "489/489 [==============================] - 295s 604ms/step - loss: 1.0308 - accuracy: 0.6397 - val_loss: 0.9481 - val_accuracy: 0.6616\n",
      "Epoch 5/250\n",
      "489/489 [==============================] - 286s 585ms/step - loss: 0.9495 - accuracy: 0.6687 - val_loss: 0.7465 - val_accuracy: 0.7375\n",
      "Epoch 6/250\n",
      "489/489 [==============================] - 293s 600ms/step - loss: 0.8858 - accuracy: 0.6932 - val_loss: 0.6689 - val_accuracy: 0.7678\n",
      "Epoch 7/250\n",
      "489/489 [==============================] - 276s 564ms/step - loss: 0.8303 - accuracy: 0.7141 - val_loss: 0.7044 - val_accuracy: 0.7558\n",
      "Epoch 8/250\n",
      "489/489 [==============================] - 272s 556ms/step - loss: 0.7940 - accuracy: 0.7280 - val_loss: 0.6174 - val_accuracy: 0.7842\n",
      "Epoch 9/250\n",
      "489/489 [==============================] - 272s 556ms/step - loss: 0.7628 - accuracy: 0.7384 - val_loss: 0.6180 - val_accuracy: 0.7814\n",
      "Epoch 10/250\n",
      "489/489 [==============================] - 274s 560ms/step - loss: 0.7362 - accuracy: 0.7466 - val_loss: 0.5948 - val_accuracy: 0.7939\n",
      "Epoch 11/250\n",
      "489/489 [==============================] - 274s 561ms/step - loss: 0.7111 - accuracy: 0.7561 - val_loss: 0.5938 - val_accuracy: 0.7968\n",
      "Epoch 12/250\n",
      "489/489 [==============================] - 273s 559ms/step - loss: 0.6872 - accuracy: 0.7644 - val_loss: 0.5679 - val_accuracy: 0.8029\n",
      "Epoch 13/250\n",
      "489/489 [==============================] - 275s 563ms/step - loss: 0.6729 - accuracy: 0.7689 - val_loss: 0.5875 - val_accuracy: 0.7982\n",
      "Epoch 14/250\n",
      "489/489 [==============================] - 276s 565ms/step - loss: 0.6591 - accuracy: 0.7725 - val_loss: 0.5565 - val_accuracy: 0.8111\n",
      "Epoch 15/250\n",
      "489/489 [==============================] - 277s 566ms/step - loss: 0.6450 - accuracy: 0.7769 - val_loss: 0.5421 - val_accuracy: 0.8137\n",
      "Epoch 16/250\n",
      "489/489 [==============================] - 300s 614ms/step - loss: 0.6362 - accuracy: 0.7815 - val_loss: 0.5618 - val_accuracy: 0.8152\n",
      "Epoch 17/250\n",
      "489/489 [==============================] - 291s 595ms/step - loss: 0.6177 - accuracy: 0.7876 - val_loss: 0.5181 - val_accuracy: 0.8240\n",
      "Epoch 18/250\n",
      "489/489 [==============================] - 290s 594ms/step - loss: 0.6041 - accuracy: 0.7920 - val_loss: 0.5043 - val_accuracy: 0.8252\n",
      "Epoch 19/250\n",
      "489/489 [==============================] - 279s 571ms/step - loss: 0.6015 - accuracy: 0.7922 - val_loss: 0.4962 - val_accuracy: 0.8360\n",
      "Epoch 20/250\n",
      "489/489 [==============================] - 280s 573ms/step - loss: 0.5902 - accuracy: 0.7971 - val_loss: 0.5323 - val_accuracy: 0.8182\n",
      "Epoch 21/250\n",
      "489/489 [==============================] - 277s 567ms/step - loss: 0.5843 - accuracy: 0.7980 - val_loss: 0.4849 - val_accuracy: 0.8367\n",
      "Epoch 22/250\n",
      "489/489 [==============================] - 276s 565ms/step - loss: 0.5786 - accuracy: 0.8005 - val_loss: 0.5059 - val_accuracy: 0.8332\n",
      "Epoch 23/250\n",
      "489/489 [==============================] - 276s 564ms/step - loss: 0.5631 - accuracy: 0.8061 - val_loss: 0.5031 - val_accuracy: 0.8314\n",
      "Epoch 24/250\n",
      "489/489 [==============================] - 289s 591ms/step - loss: 0.5623 - accuracy: 0.8078 - val_loss: 0.4752 - val_accuracy: 0.8357\n",
      "Epoch 25/250\n",
      "489/489 [==============================] - 296s 606ms/step - loss: 0.5502 - accuracy: 0.8102 - val_loss: 0.4754 - val_accuracy: 0.8389\n",
      "Epoch 26/250\n",
      "489/489 [==============================] - 278s 568ms/step - loss: 0.5493 - accuracy: 0.8113 - val_loss: 0.4801 - val_accuracy: 0.8378\n",
      "Epoch 27/250\n",
      "489/489 [==============================] - 278s 568ms/step - loss: 0.5460 - accuracy: 0.8117 - val_loss: 0.4691 - val_accuracy: 0.8414\n",
      "Epoch 28/250\n",
      "489/489 [==============================] - 277s 567ms/step - loss: 0.5339 - accuracy: 0.8155 - val_loss: 0.4796 - val_accuracy: 0.8382\n",
      "Epoch 29/250\n",
      "489/489 [==============================] - 286s 585ms/step - loss: 0.5358 - accuracy: 0.8156 - val_loss: 0.4914 - val_accuracy: 0.8353\n",
      "Epoch 30/250\n",
      "489/489 [==============================] - 278s 569ms/step - loss: 0.5277 - accuracy: 0.8173 - val_loss: 0.4709 - val_accuracy: 0.8446\n",
      "Epoch 31/250\n",
      "489/489 [==============================] - 278s 568ms/step - loss: 0.5220 - accuracy: 0.8190 - val_loss: 0.4758 - val_accuracy: 0.8442\n",
      "Epoch 32/250\n",
      "489/489 [==============================] - 279s 571ms/step - loss: 0.5201 - accuracy: 0.8200 - val_loss: 0.4904 - val_accuracy: 0.8355\n",
      "Epoch 33/250\n",
      "489/489 [==============================] - 282s 577ms/step - loss: 0.5101 - accuracy: 0.8243 - val_loss: 0.4762 - val_accuracy: 0.8434\n",
      "Epoch 34/250\n",
      "489/489 [==============================] - 280s 572ms/step - loss: 0.5092 - accuracy: 0.8237 - val_loss: 0.4734 - val_accuracy: 0.8451\n",
      "Epoch 35/250\n",
      "489/489 [==============================] - 280s 572ms/step - loss: 0.5012 - accuracy: 0.8266 - val_loss: 0.4590 - val_accuracy: 0.8502\n",
      "Epoch 36/250\n",
      "489/489 [==============================] - 281s 575ms/step - loss: 0.5032 - accuracy: 0.8262 - val_loss: 0.4632 - val_accuracy: 0.8467\n",
      "Epoch 37/250\n",
      "489/489 [==============================] - 280s 572ms/step - loss: 0.4959 - accuracy: 0.8276 - val_loss: 0.4848 - val_accuracy: 0.8409\n",
      "Epoch 38/250\n",
      "489/489 [==============================] - 297s 608ms/step - loss: 0.4922 - accuracy: 0.8294 - val_loss: 0.4599 - val_accuracy: 0.8496\n",
      "Epoch 39/250\n",
      "489/489 [==============================] - 294s 601ms/step - loss: 0.4927 - accuracy: 0.8300 - val_loss: 0.4802 - val_accuracy: 0.8416\n",
      "Epoch 40/250\n",
      "489/489 [==============================] - 306s 625ms/step - loss: 0.4887 - accuracy: 0.8310 - val_loss: 0.4474 - val_accuracy: 0.8508\n",
      "Epoch 41/250\n",
      "489/489 [==============================] - 302s 618ms/step - loss: 0.4879 - accuracy: 0.8319 - val_loss: 0.4675 - val_accuracy: 0.8450\n",
      "Epoch 42/250\n",
      "489/489 [==============================] - 306s 626ms/step - loss: 0.4832 - accuracy: 0.8328 - val_loss: 0.4679 - val_accuracy: 0.8446\n",
      "Epoch 43/250\n",
      "489/489 [==============================] - 296s 606ms/step - loss: 0.4764 - accuracy: 0.8361 - val_loss: 0.4585 - val_accuracy: 0.8541\n",
      "Epoch 44/250\n",
      "489/489 [==============================] - 299s 612ms/step - loss: 0.4754 - accuracy: 0.8365 - val_loss: 0.4649 - val_accuracy: 0.8455\n",
      "Epoch 45/250\n",
      "489/489 [==============================] - 293s 600ms/step - loss: 0.4753 - accuracy: 0.8355 - val_loss: 0.4395 - val_accuracy: 0.8544\n",
      "Epoch 46/250\n",
      "489/489 [==============================] - 297s 608ms/step - loss: 0.4663 - accuracy: 0.8386 - val_loss: 0.4654 - val_accuracy: 0.8479\n",
      "Epoch 47/250\n",
      "489/489 [==============================] - 289s 590ms/step - loss: 0.4637 - accuracy: 0.8394 - val_loss: 0.4846 - val_accuracy: 0.8435\n",
      "Epoch 48/250\n",
      "489/489 [==============================] - 289s 592ms/step - loss: 0.4638 - accuracy: 0.8404 - val_loss: 0.4783 - val_accuracy: 0.8475\n",
      "Epoch 49/250\n",
      "489/489 [==============================] - 287s 586ms/step - loss: 0.4652 - accuracy: 0.8402 - val_loss: 0.4510 - val_accuracy: 0.8514\n",
      "Epoch 50/250\n",
      "489/489 [==============================] - 283s 578ms/step - loss: 0.4605 - accuracy: 0.8401 - val_loss: 0.4590 - val_accuracy: 0.8522\n",
      "Epoch 51/250\n",
      "489/489 [==============================] - 283s 578ms/step - loss: 0.4579 - accuracy: 0.8416 - val_loss: 0.4358 - val_accuracy: 0.8545\n",
      "Epoch 52/250\n",
      "489/489 [==============================] - 284s 581ms/step - loss: 0.4524 - accuracy: 0.8432 - val_loss: 0.4428 - val_accuracy: 0.8559\n",
      "Epoch 53/250\n",
      "489/489 [==============================] - 284s 581ms/step - loss: 0.4534 - accuracy: 0.8422 - val_loss: 0.4692 - val_accuracy: 0.8451\n",
      "Epoch 54/250\n",
      "489/489 [==============================] - 283s 579ms/step - loss: 0.4502 - accuracy: 0.8445 - val_loss: 0.4488 - val_accuracy: 0.8558\n",
      "Epoch 55/250\n",
      "489/489 [==============================] - 286s 584ms/step - loss: 0.4499 - accuracy: 0.8445 - val_loss: 0.4715 - val_accuracy: 0.8487\n",
      "Epoch 56/250\n",
      "489/489 [==============================] - 284s 582ms/step - loss: 0.4508 - accuracy: 0.8441 - val_loss: 0.4787 - val_accuracy: 0.8464\n",
      "Epoch 57/250\n",
      "489/489 [==============================] - 296s 605ms/step - loss: 0.4469 - accuracy: 0.8450 - val_loss: 0.4597 - val_accuracy: 0.8509\n",
      "Epoch 58/250\n",
      "489/489 [==============================] - 288s 588ms/step - loss: 0.4437 - accuracy: 0.8468 - val_loss: 0.4441 - val_accuracy: 0.8576\n",
      "Epoch 59/250\n",
      "489/489 [==============================] - 292s 598ms/step - loss: 0.4356 - accuracy: 0.8497 - val_loss: 0.4822 - val_accuracy: 0.8440\n",
      "Epoch 60/250\n",
      "489/489 [==============================] - 302s 618ms/step - loss: 0.4389 - accuracy: 0.8480 - val_loss: 0.4796 - val_accuracy: 0.8459\n",
      "Epoch 61/250\n",
      "489/489 [==============================] - 292s 597ms/step - loss: 0.4430 - accuracy: 0.8473 - val_loss: 0.4439 - val_accuracy: 0.8565\n",
      "Epoch 62/250\n",
      "489/489 [==============================] - 311s 637ms/step - loss: 0.4326 - accuracy: 0.8501 - val_loss: 0.4568 - val_accuracy: 0.8493\n",
      "Epoch 63/250\n",
      "489/489 [==============================] - 299s 612ms/step - loss: 0.4328 - accuracy: 0.8489 - val_loss: 0.4477 - val_accuracy: 0.8574\n",
      "Epoch 64/250\n",
      "489/489 [==============================] - 306s 626ms/step - loss: 0.4342 - accuracy: 0.8507 - val_loss: 0.4264 - val_accuracy: 0.8590\n",
      "Epoch 65/250\n",
      "290/489 [================>.............] - ETA: 2:01 - loss: 0.4346 - accuracy: 0.8488"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time=datetime.now()\n",
    "\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "hist=cnn.fit(x_train, y_train, batch_size=256, epochs=250, validation_data=(x_test, y_test))\n",
    "\n",
    "end_time=datetime.now()\n",
    "\n",
    "print('Elapsed Time => ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1d224-8fe3-4b7f-a576-098bf1d9ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fb3e4-1573-4227-922b-d0f22e339b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuraty Trend')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'],loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 훈련데이터 뿐만 아니라 validation 데이터와도 따라감 -> overfitting 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16e1e3-f681-4c1e-974e-20126682b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Accuraty Trend')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'],loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
